{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Initialize"],"metadata":{"id":"mFim22UaIBGO"}},{"cell_type":"code","source":["import numpy as np\n","from scipy.linalg import hadamard\n","from google.colab import drive\n","import tensorflow as tf\n","from skimage.util import random_noise\n","from scipy.ndimage import gaussian_filter\n","from PIL import Image\n","import cv2 as cv\n","import io\n","from scipy.ndimage import shift as my_shift_attack\n","import torch\n","\n","\n","\n","drive.mount('/content/drive')\n","%run '/content/drive/MyDrive/Colab Notebooks/CNN_WavePattern_Noise/Fourier_Test/Watermarking_Classes.ipynb'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4p6Xv0RrAe0I","executionInfo":{"status":"ok","timestamp":1753280048384,"user_tz":-60,"elapsed":1025,"user":{"displayName":"Arash F.Tafreshi","userId":"09297385215137091684"}},"outputId":"6b786672-3831-483f-b70c-71e25ac339c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Watermarking"],"metadata":{"id":"-eAEw4OCIDMJ"}},{"cell_type":"code","source":["class Watermarking:\n","    def __init__(self, im, watermark_bits):\n","        self.im = im\n","        self.watermark_bits = watermark_bits\n","\n","    def embedding(self, G, pn_array):\n","        # Compose watermark from first two bits (assumed 0 or 1)\n","        watermark = self.watermark_bits[0] * 2 + self.watermark_bits[1]\n","        watermarked = self._data_embedding(watermark, G, pn_array)\n","        return watermarked\n","\n","    def reconstruction(self, pn_array):\n","        reconstructed_watermark = self._data_reconstruction(self.im, pn_array)\n","        bits_array = np.vstack((reconstructed_watermark // 2, reconstructed_watermark % 2)).T\n","\n","        #reconstructed_bits = reconstructed_watermark // 2, reconstructed_watermark % 2\n","        return bits_array\n","\n","    def _data_embedding(self, watermark, G, pn_array):\n","        if watermark > pn_array.shape[0] - 1:\n","            return np.zeros(self.im.shape)\n","\n","        w = self.im + G * pn_array[watermark]\n","        w = np.clip(w, 0, 1)\n","        return w\n","\n","    def _data_reconstruction(self, watermarked_im, pn_array):\n","        M = pn_array.shape[0]\n","        correlation_coefficients = np.zeros(M)\n","\n","        for i in range(M):\n","            pn = pn_array[i]\n","            correlation_coefficients[i] = np.abs(np.mean(watermarked_im * pn))\n","\n","        return np.argmax(correlation_coefficients)\n"],"metadata":{"id":"DhFblKAP7OD6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DCT Watermarking"],"metadata":{"id":"BluBkgyaKH0-"}},{"cell_type":"code","source":["import numpy as np\n","import cv2 as cv\n","\n","class DCTWatermarking:\n","    def __init__(self, im, watermark_bits):\n","        self.im = im\n","        self.watermark_bits = watermark_bits  # should be length-2 binary array\n","\n","\n","    def embedding(self, g, pn_array):\n","        # Map the 2-bit watermark to an integer index (0-3)\n","        watermark_index = self.watermark_bits[0] * 2 + self.watermark_bits[1]\n","        pn = pn_array[watermark_index]\n","\n","        # Convert image and PN pattern to float32\n","        _im = np.float32(self.im)\n","        _pn = np.float32(pn)\n","\n","        # Apply DCT\n","        dct_im = cv.dct(_im)\n","        dct_pn = cv.dct(_pn)\n","\n","        # Embed watermark\n","        watermarked_dct = dct_im + g * dct_pn\n","\n","        # Inverse DCT to get watermarked image\n","        watermarked_img = cv.idct(watermarked_dct)\n","        return np.clip(watermarked_img, 0, 255).astype(np.uint8)\n","\n","\n","    def reconstruction(self, pn_array):\n","        _watermarked = np.float32(self.im)\n","        dct_watermarked = cv.dct(_watermarked)\n","\n","        correlation_coefficients = []\n","\n","        for i in range(len(pn_array)):\n","            pn = np.float32(pn_array[i])\n","            dct_pn = cv.dct(pn)\n","            corr = np.vdot(dct_watermarked, dct_pn)\n","            correlation_coefficients.append(np.abs(corr))  # use abs to be safe\n","\n","        reconstructed_watermark = np.argmax(correlation_coefficients)\n","        bits_array = np.array([reconstructed_watermark // 2, reconstructed_watermark % 2])\n","        return bits_array\n"],"metadata":{"id":"mqrKGV1fKLat"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PN Sequences"],"metadata":{"id":"80Modhe1IFD6"}},{"cell_type":"code","source":["class PNSequences:\n","  def __init__(self, im):\n","    self.im = im\n","\n","\n","  def created_traditional_pn_array(self):\n","    return np.random.choice([1, -1], size=(4, self.im.shape[0], self.im.shape[0]))\n","\n","\n","  def created_hadamard_pn_array(self):\n","    pn_size = self.im.shape[0]\n","    H = hadamard(pn_size)\n","    pn = np.random.choice([1, -1], size=(pn_size, pn_size))\n","\n","    pn_array = np.zeros((4, pn_size, pn_size))\n","    pn_array[0] = pn * H[0]\n","    pn_array[1] = pn * H[1]\n","    pn_array[2] = pn * H[2]\n","    pn_array[3] = pn * H[3]\n","\n","    return pn_array\n","\n","\n","  def created_advanced_pn_array(self, G):\n","\n","    image_size = self.im.shape[0]\n","    pn_array = np.zeros((4 , image_size, image_size))\n","\n","    index = 0\n","    while(True):\n","\n","      pn = np.random.choice([-1, 1], size=(image_size, image_size))\n","      r = self._check_statistical_properties(pn, G)\n","\n","      if(r == True):\n","        pn_array[index] = pn\n","        index += 1\n","\n","      if(index == 4):\n","        break\n","\n","    return pn_array\n","\n","\n","  def _check_statistical_properties(self, pn, G):\n","\n","    image_size = self.im.shape[0]\n","    r = np.abs(np.mean(self.im * pn))\n","\n","    if(r > G): # Advanced SSIS\n","      return False\n","\n","    return True\n","\n","\n"],"metadata":{"id":"J2I0xwbSBBG_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# CNN Watermarking"],"metadata":{"id":"Nk4adRwuIIpp"}},{"cell_type":"code","source":["class CNNWatermarking:\n","    def __init__(self, im, mask_ratio):\n","        self.im = im\n","        self.mask_ratio = mask_ratio\n","\n","    def embedding(self, watermark_bits):\n","        image_size = self.im.shape[0]\n","\n","        # Create PN pattern\n","        data = Data(1, image_size, self.mask_ratio)\n","        r = watermark_bits[0] * 2 + watermark_bits[1]\n","\n","        freq_map = {0: 5, 1: 10, 2: 15, 3: 20}\n","        freq = freq_map.get(r, 5)  # default to 5 if invalid r\n","\n","        pn = data.created_wave_pattern(freq)\n","\n","        # Watermarking\n","        tr = Transmitter(self.im, pn, self.mask_ratio)\n","        watermarked = tr.Watermarking()\n","\n","        return watermarked\n","\n","\n","    def reconstruction(self, model):\n","      watermarked = self.im\n","\n","      # Reconstruct PN\n","      re = Receiver(watermarked, self.mask_ratio)\n","      reconstructed_pn = re.PN_Reconstruction()  # shape (128, 128)\n","\n","      # Prepare input for model (NCHW)\n","      input_data = reconstructed_pn[np.newaxis, ..., np.newaxis]  # (1, 128, 128, 1)\n","      input_data = np.transpose(input_data, (0, 3, 1, 2))        # (1, 1, 128, 128)\n","\n","      input_tensor = torch.tensor(input_data, dtype=torch.float32)\n","\n","      model.eval()\n","      with torch.no_grad():\n","          output = model(input_tensor)\n","          predicted_class = torch.argmax(output, dim=1).item()\n","\n","      return np.array([predicted_class // 2, predicted_class % 2])\n","\n","\n","    def reconstruction_with_confidence_score(self, model):\n","      watermarked = self.im\n","\n","      # Reconstruct PN\n","      re = Receiver(watermarked, self.mask_ratio)\n","      reconstructed_pn = re.PN_Reconstruction()  # shape (128, 128)\n","\n","      # Prepare input for model (NCHW)\n","      input_data = reconstructed_pn[np.newaxis, ..., np.newaxis]  # (1, 128, 128, 1)\n","      input_data = np.transpose(input_data, (0, 3, 1, 2))        # (1, 1, 128, 128)\n","      input_tensor = torch.tensor(input_data, dtype=torch.float32)\n","\n","      model.eval()\n","      with torch.no_grad():\n","          output = model(input_tensor)                   # shape (1, 4)\n","          probs = torch.softmax(output, dim=1)           # (1, 4)\n","          predicted_class = torch.argmax(probs, dim=1).item()\n","          confidence = torch.max(probs, dim=1).values.item()\n","\n","      bits = np.array([predicted_class // 2, predicted_class % 2])\n","      return bits, confidence\n","\n","\n"],"metadata":{"id":"28E5-8WUDxoB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Channel"],"metadata":{"id":"25uVJj3TG7hg"}},{"cell_type":"code","source":["class Channel:\n","    def __init__(self, im):\n","        self.im = im\n","\n","\n","    def x_shift_attack(self, x):\n","      shifted_image = my_shift_attack(self.im, shift=(0, x))  # shift x pixels along x-axis\n","      return shifted_image\n","\n","\n","    def rotation_attack(self, angle):\n","\n","      h, w = self.im.shape\n","      center = (w // 2, h // 2)\n","\n","      # Get rotation matrix\n","      M = cv.getRotationMatrix2D(center, angle, 1.0)\n","\n","      # Apply affine warp\n","      rotated = cv.warpAffine(self.im, M, (w, h), flags = cv.INTER_LINEAR, borderMode = cv.BORDER_REFLECT_101)\n","\n","      return rotated\n","\n","\n","    def add_guassian_noise(self, input_mean, standard_deviation):\n","      noise = np.random.normal(input_mean, standard_deviation, self.im.shape)\n","\n","        # Apply Gaussian blur to create correlated noise\n","      correlated_noise = gaussian_filter(noise, sigma=1)\n","\n","      noisy_image = self.im + correlated_noise\n","      noisy_image = np.clip(noisy_image, 0, 1)\n","      return noisy_image\n","\n","\n","    def add_random_noise(self , noise_strength):\n","\n","      noise = np.random.normal(loc=0, scale=1, size=self.im.shape)  # Generate standard normal noise\n","      noise = (noise - np.min(noise)) / (np.max(noise) - np.min(noise))  # Normalize noise to [0,1]\n","      noise = 2 * noise_strength * (noise - 0.5)  # Scale to [-noise_strength, noise_strength]\n","\n","      # Apply Gaussian blur to create correlated noise\n","      correlated_noise = gaussian_filter(noise, sigma=1)\n","\n","      # Add noise to the image and clip to valid range\n","      image_noisy = self.im + correlated_noise\n","      image_noisy = np.clip(image_noisy, 0, 1)\n","      return image_noisy\n","\n","\n","    def add_salt_and_pepper_noise(self, noise_ratio):\n","      noisy_image = self.im.copy()\n","\n","      if len(noisy_image.shape) == 2:\n","          height, width = noisy_image.shape\n","      elif len(noisy_image.shape) == 3 and noisy_image.shape[2] == 1:\n","          height, width = noisy_image.shape[:2]\n","      else:\n","          raise ValueError(\"Expected grayscale image with shape (H, W) or (H, W, 1)\")\n","\n","      total_pixels = height * width\n","      num_noisy = int(noise_ratio * total_pixels)\n","\n","      # Generate random pixel coordinates\n","      coords = np.unravel_index(\n","          np.random.choice(total_pixels, num_noisy, replace=False),\n","          (height, width)\n","      )\n","\n","      # Apply noise\n","      half = num_noisy // 2\n","      noisy_image[coords[0][:half], coords[1][:half]] = np.random.uniform(0.0, 0.2)      # Pepper\n","      noisy_image[coords[0][half:], coords[1][half:]] = np.random.uniform(0.8, 1.0)     # Salt\n","\n","      return noisy_image\n","\n","\n","\n","    def blur_image(self, filter_size):\n","      blurred = cv.blur(self.im, (filter_size, filter_size))\n","      return blurred\n","\n","\n","    def crop_image(self, crop_size):\n","      height, width = self.im.shape\n","      scale = np.sqrt(crop_size)\n","      new_height = int(height * scale)\n","      new_width = int(width * scale)\n","      start_y = (height - new_height) // 2\n","      start_x = (width - new_width) // 2\n","      cropped_img = self.im[start_y:start_y+new_height, start_x:start_x+new_width]\n","\n","\n","      output_size=(self.im.shape[0], self.im.shape[0])\n","      resized = cv.resize(cropped_img, output_size, interpolation=cv.INTER_AREA)\n","      return resized\n","\n","\n","    def jpeg_compress_grayscale_image(self, quality):\n","\n","      # Ensure the image is in 8-bit format\n","      if self.im.max() <= 1.0:\n","          self.im = (self.im * 255).astype(np.uint8)\n","      else:\n","          self.im = self.im.astype(np.uint8)\n","\n","      # Convert NumPy array to PIL grayscale image\n","      # pil_image = Image.fromarray(self.im, mode='L')  # 'L' = 8-bit grayscale\n","      pil_image = Image.fromarray(self.im).convert('L')\n","\n","      # Compress the image using JPEG in memory\n","      buffer = io.BytesIO()\n","      pil_image.save(buffer, format='JPEG', quality=quality)\n","      buffer.seek(0)\n","\n","      # Reload the image from buffer\n","      compressed_pil = Image.open(buffer).convert('L')  # Ensure grayscale\n","      compressed_np = np.array(compressed_pil)\n","\n","      return compressed_np\n","\n","\n","\n","    def brightness_attack(self , brightness_value):\n","      \"\"\"\n","      Applies a brightness attack to a normalized grayscale image.\n","\n","      Parameters:\n","      - image (np.ndarray): Normalized grayscale image (values in [0.0, 1.0], dtype float32 or float64).\n","      - brightness_value (float): Amount to increase brightness (e.g., 0.1 for a mild attack).\n","\n","      Returns:\n","      - np.ndarray: Brightness-attacked image, clipped to [0.0, 1.0], same dtype as input.\n","      \"\"\"\n","      if not np.issubdtype(self.im.dtype, np.floating):\n","          raise ValueError(\"Input image must be of float type with values in [0.0, 1.0]\")\n","\n","      # Add brightness and clip\n","      bright_image = self.im + brightness_value\n","      bright_image = np.clip(bright_image, 0.0, 1.0)\n","\n","      return bright_image.astype(self.im.dtype)\n","\n","\n","    def contrast_attack(self, contrast_factor):\n","      \"\"\"\n","      Applies contrast adjustment to a normalized grayscale image (values in [0, 1]).\n","\n","      Parameters:\n","      - image: 2D numpy array (normalized grayscale image)\n","      - contrast_factor: float\n","          - >1.0 increases contrast\n","          - <1.0 decreases contrast (e.g., 0.5 reduces contrast)\n","          - =1.0 leaves image unchanged\n","\n","      Returns:\n","      - contrast_adjusted: 2D numpy array, same shape as input, clipped to [0, 1]\n","      \"\"\"\n","      #if not np.all((image >= 0) & (image <= 1)):\n","        #raise ValueError(\"Input image must be normalized to the range [0, 1].\")\n","\n","\n","      mean_intensity = np.mean(self.im)\n","      contrast_adjusted = (self.im - mean_intensity) * contrast_factor + mean_intensity\n","      contrast_adjusted = np.clip(contrast_adjusted, 0, 1)\n","\n","      return contrast_adjusted\n"],"metadata":{"id":"4PbBM4rJG9jP","executionInfo":{"status":"ok","timestamp":1762345701055,"user_tz":0,"elapsed":43,"user":{"displayName":"Arash F.Tafreshi","userId":"09297385215137091684"}}},"execution_count":7,"outputs":[]}]}